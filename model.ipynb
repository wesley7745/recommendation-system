{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         course_detail  course_level\n",
      "0                     Beginner · Course · 1 - 3 Months      Beginner\n",
      "1    Beginner · Professional Certificate · 3 - 6 Mo...      Beginner\n",
      "2         Intermediate · Specialization · 1 - 3 Months  Intermediate\n",
      "3             Beginner · Specialization · 1 - 3 Months      Beginner\n",
      "4                  Intermediate · Course · 1 - 4 Weeks  Intermediate\n",
      "..                                                 ...           ...\n",
      "631                   Beginner · Course · 1 - 3 Months      Beginner\n",
      "632                   Beginner · Course · 1 - 3 Months      Beginner\n",
      "633       Intermediate · Specialization · 3 - 6 Months  Intermediate\n",
      "634                   Beginner · Course · 1 - 3 Months      Beginner\n",
      "635                   Beginner · Course · 1 - 3 Months      Beginner\n",
      "\n",
      "[636 rows x 2 columns]\n",
      "分級提取完成，結果已保存到新的Excel文件。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 讀取Excel文件\n",
    "file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/coursera爬蟲/所有課程資訊/course_data_AI_cleaned.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 定義一個函數來提取分級部分\n",
    "def extract_level(detail):\n",
    "    if isinstance(detail, str):\n",
    "        return detail.split('·')[0].strip()\n",
    "    return None\n",
    "\n",
    "# 應用該函數來創建新的一列\n",
    "df['course_level'] = df['course_detail'].apply(extract_level)\n",
    "\n",
    "# 檢查新的一列\n",
    "print(df[['course_detail', 'course_level']])\n",
    "\n",
    "# 將結果保存到新的Excel文件\n",
    "output_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_AI_with_levels.xlsx'\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(\"分級提取完成，結果已保存到新的Excel文件。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\WCHuang8\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.787 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.390625\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.26      0.26        35\n",
      "           1       0.43      0.52      0.47        44\n",
      "           2       0.46      0.37      0.41        49\n",
      "\n",
      "    accuracy                           0.39       128\n",
      "   macro avg       0.38      0.38      0.38       128\n",
      "weighted avg       0.39      0.39      0.39       128\n",
      "\n",
      "                                          course_title  \\\n",
      "0                                 Google AI Essentials   \n",
      "1                                     IBM AI Developer   \n",
      "2          Introduction to Generative AI Learning Path   \n",
      "3                      IBM AI Foundations for Business   \n",
      "4             Generative AI with Large Language Models   \n",
      "..                                                 ...   \n",
      "631            Data Analysis with Spreadsheets and SQL   \n",
      "632  Project Management Foundations, Initiation, an...   \n",
      "633                  International Business Essentials   \n",
      "634             Leading transformations: Manage change   \n",
      "635                            Becoming a Sports Agent   \n",
      "\n",
      "                                              keywords course_level  \\\n",
      "0    [essentials, google, solving, problem, critica...            高   \n",
      "1    [cloud, software, learning, computer, programm...            中   \n",
      "2    [path, learning, generative, introduction, to,...            高   \n",
      "3    [learning, data, business, machine, management...            中   \n",
      "4    [language, large, models, natural, processing,...            中   \n",
      "..                                                 ...          ...   \n",
      "631  [sql, spreadsheets, data, tableau, analysis, w...            低   \n",
      "632  [project, initiation, management, foundations,...            低   \n",
      "633  [management, development, business, statistics...            低   \n",
      "634  [change, manage, transformations, leading, inf...            低   \n",
      "635  [agent, sports, becoming, negotiation, brand, ...            高   \n",
      "\n",
      "    predicted_course_level  \n",
      "0                        高  \n",
      "1                        中  \n",
      "2                        低  \n",
      "3                        高  \n",
      "4                        中  \n",
      "..                     ...  \n",
      "631                      低  \n",
      "632                      中  \n",
      "633                      低  \n",
      "634                      低  \n",
      "635                      高  \n",
      "\n",
      "[636 rows x 4 columns]\n",
      "課程分級完成，結果已保存到新的Excel文件。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 讀取Excel文件\n",
    "file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/coursera爬蟲/所有課程資訊/course_data_AI_cleaned.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 刪除包含缺漏值（NaN）的行\n",
    "df = df.dropna()\n",
    "\n",
    "# 提取課程名稱和介紹文本\n",
    "df['text'] = df['course_title'] + ' ' + df['skill_gain'] + ' ' + df['course_detail']\n",
    "\n",
    "# 分詞\n",
    "df['words'] = df['text'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "# 使用TF-IDF提取關鍵詞\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['words'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 提取每個課程的關鍵詞\n",
    "def get_top_keywords(tfidf_row, feature_names, top_n=10):\n",
    "    sorted_nzs = tfidf_row.nonzero()[1][tfidf_row.data.argsort()[::-1]]\n",
    "    top_keywords = [feature_names[i] for i in sorted_nzs[:top_n]]\n",
    "    return top_keywords\n",
    "\n",
    "df['keywords'] = df.apply(lambda row: get_top_keywords(tfidf_matrix[row.name], feature_names), axis=1)\n",
    "\n",
    "# 假設我們有一列 'course_level' 代表課程的等級（高/中/低）\n",
    "# 這裡我們隨機生成一些示例數據\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "df['course_level'] = np.random.choice(['高', '中', '低'], size=len(df))\n",
    "\n",
    "# 將 'course_level' 映射到數值標籤\n",
    "label_mapping = {'低': 0, '中': 1, '高': 2}\n",
    "df['label'] = df['course_level'].map(label_mapping)\n",
    "\n",
    "# 切分數據集\n",
    "X = tfidf_matrix\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 訓練模型\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 評估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 輸出包含關鍵詞和等級的課程資料\n",
    "df['predicted_level'] = clf.predict(tfidf_matrix)\n",
    "df['predicted_course_level'] = df['predicted_level'].map({0: '低', 1: '中', 2: '高'})\n",
    "print(df[['course_title', 'keywords', 'course_level', 'predicted_course_level']])\n",
    "\n",
    "# 如果需要將結果保存為新的Excel文件\n",
    "output_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_AI_with_predictions.xlsx'\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(\"課程分級完成，結果已保存到新的Excel文件。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coursera 80% 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 劃分數據集\n",
    "將數據集劃分為訓練集（80%）和測試集（20%），以便我們可以評估模型的性能。\n",
    "\n",
    "4. 訓練模型\n",
    "使用訓練數據來訓練隨機森林分類器。隨機森林通過以下步驟進行建模：\n",
    "\n",
    "構建多棵決策樹：隨機森林通過對原始數據進行多次有放回的隨機抽樣（稱為Bootstrap樣本）來構建多棵決策樹。每棵樹都是在不同的訓練樣本上訓練的。\n",
    "\n",
    "隨機特徵選擇：在每棵決策樹的每個節點上，隨機森林會隨機選擇一個特徵子集，並在這個特徵子集上選擇最佳分割點，從而增加樹之間的多樣性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix shape: (600, 903)\n",
      "Labels shape: (600,)\n",
      "X_train shape: (480, 903)\n",
      "X_test shape: (120, 903)\n",
      "y_train shape: (480,)\n",
      "y_test shape: (120,)\n",
      "Accuracy: 0.9916666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        85\n",
      "         1.0       0.97      1.00      0.98        30\n",
      "         2.0       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.99       120\n",
      "   macro avg       0.99      0.93      0.96       120\n",
      "weighted avg       0.99      0.99      0.99       120\n",
      "\n",
      "y_test index: [112, 434, 600, 78, 187, 292, 10, 492, 79, 357, 56, 120, 111, 624, 379, 242, 30, 219, 190, 87, 2, 623, 564, 632, 378, 569, 73, 139, 589, 454, 631, 167, 83, 265, 198, 473, 136, 542, 458, 283, 374, 29, 532, 605, 24, 188, 497, 106, 64, 515, 253, 256, 103, 588, 627, 365, 216, 169, 141, 201, 77, 180, 337, 565, 579, 71, 596, 625, 82, 324, 312, 6, 439, 384, 445, 566, 320, 246, 593, 448, 294, 442, 634, 371, 74, 39, 159, 225, 380, 217, 243, 577, 61, 308, 267, 288, 236, 11, 427, 84, 91, 215, 567, 343, 80, 450, 144, 289, 276, 429, 205, 485, 611, 620, 381, 413, 348, 152, 519, 456]\n",
      "模型訓練和預測完成，結果已保存到新的Excel文件。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import jieba\n",
    "\n",
    "# 讀取Excel文件\n",
    "file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_AI_with_levels.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 確保數據中沒有缺失值\n",
    "df = df.dropna()\n",
    "\n",
    "# 提取文本特徵\n",
    "df['text'] = df['course_title'] + ' ' + df['skill_gain'] + ' ' + df['course_detail']\n",
    "\n",
    "# 分詞\n",
    "df['words'] = df['text'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "# 映射課程級別到數值標籤\n",
    "label_mapping = {'Beginner': 0, 'Intermediate': 1, 'Advanced': 2}  # 假設有三個級別\n",
    "df['label'] = df['course_level'].map(label_mapping)\n",
    "\n",
    "# 檢查是否存在NaN值並刪除\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# 使用TF-IDF提取文本特徵\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['words'])\n",
    "\n",
    "# 檢查數據集大小是否一致\n",
    "print(f\"TF-IDF Matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Labels shape: {df['label'].shape}\")\n",
    "\n",
    "# 劃分數據集，80%訓練數據和20%測試數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 檢查劃分後的數據集大小\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# 訓練隨機森林模型\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 評估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 確保索引的一致性\n",
    "print(f\"y_test index: {list(y_test.index)}\")\n",
    "\n",
    "# 獲取測試數據的索引\n",
    "test_indices = y_test.index\n",
    "\n",
    "# 如果需要將測試結果保存到Excel文件\n",
    "df_test = df.loc[test_indices].copy()  # 使用 .loc 確保索引一致性\n",
    "df_test['predicted_label'] = y_pred\n",
    "df_test['predicted_course_level'] = df_test['predicted_label'].map({0: 'Beginner', 1: 'Intermediate', 2: 'Advanced'})\n",
    "\n",
    "test_output_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_test_with_predictions.xlsx'\n",
    "df_test.to_excel(test_output_file_path, index=False)\n",
    "\n",
    "print(\"模型訓練和預測完成，結果已保存到新的Excel文件。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Udemy vs Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.7333333333333333\n",
      "Classification Report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.94      0.84        85\n",
      "         1.0       0.53      0.27      0.36        30\n",
      "         2.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.73       120\n",
      "   macro avg       0.43      0.40      0.40       120\n",
      "weighted avg       0.67      0.73      0.69       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測完成，結果已保存到新的Excel文件。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import jieba\n",
    "\n",
    "# 讀取之前的資料集並訓練模型\n",
    "train_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_AI_with_levels.xlsx'\n",
    "df_train = pd.read_excel(train_file_path)\n",
    "\n",
    "# 確保數據中沒有缺失值\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# 提取文本特徵\n",
    "df_train['text'] = df_train['course_title'] + ' ' + df_train['skill_gain']\n",
    "\n",
    "# 分詞\n",
    "df_train['words'] = df_train['text'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "# 映射課程級別到數值標籤\n",
    "label_mapping = {'Beginner': 0, 'Intermediate': 1, 'Advanced': 2}\n",
    "df_train['label'] = df_train['course_level'].map(label_mapping)\n",
    "\n",
    "# 檢查是否存在NaN值並刪除\n",
    "df_train = df_train.dropna(subset=['label'])\n",
    "\n",
    "# 使用TF-IDF提取文本特徵\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix_train = vectorizer.fit_transform(df_train['words'])\n",
    "\n",
    "# 劃分數據集，80%訓練數據和20%測試數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix_train, df_train['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 訓練隨機森林模型\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 在測試集上進行預測\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 評估模型\n",
    "print(\"Accuracy on test data:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report on test data:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 讀取新的資料集\n",
    "new_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/UdemyCourses.xlsx'\n",
    "df_new = pd.read_excel(new_file_path)\n",
    "\n",
    "# 確保數據中沒有缺失值\n",
    "df_new = df_new.dropna()\n",
    "\n",
    "# 提取文本特徵\n",
    "df_new['text'] = df_new['course_title'] + ' ' + df_new['skill_gain']\n",
    "\n",
    "# 分詞\n",
    "df_new['words'] = df_new['text'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "# 使用之前的TF-IDF向量化器轉換新資料集\n",
    "tfidf_matrix_new = vectorizer.transform(df_new['words'])\n",
    "\n",
    "# 使用訓練好的模型進行預測\n",
    "predicted_labels = clf.predict(tfidf_matrix_new)\n",
    "\n",
    "# 將預測結果映射回課程級別\n",
    "df_new['predicted_label'] = predicted_labels\n",
    "df_new['predicted_course_level'] = df_new['predicted_label'].map({0: 'Beginner', 1: 'Intermediate', 2: 'Advanced'})\n",
    "\n",
    "# 保存預測結果到新的Excel文件\n",
    "output_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/UdemyCourses_with_predictions.xlsx'\n",
    "df_new.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(\"預測完成，結果已保存到新的Excel文件。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Udemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import jieba\n",
    "\n",
    "# 讀取Excel文件\n",
    "file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/UdemyCourses.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 確保數據中沒有缺失值\n",
    "df = df.dropna()\n",
    "\n",
    "# 提取文本特徵\n",
    "df['text'] = df['course_title'] + ' ' + df['skill_gain'] \n",
    "\n",
    "# 分詞\n",
    "df['words'] = df['text'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "# 映射課程級別到數值標籤\n",
    "label_mapping = {'Beginner': 0, 'Intermediate': 1, 'Advanced': 2}\n",
    "df['label'] = df['course_level'].map(label_mapping)\n",
    "\n",
    "# 檢查是否存在NaN值並刪除\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# 使用TF-IDF提取文本特徵\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['words'])\n",
    "\n",
    "# 檢查數據集大小是否一致\n",
    "print(f\"TF-IDF Matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Labels shape: {df['label'].shape}\")\n",
    "\n",
    "# 劃分數據集，80%訓練數據和20%測試數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 檢查劃分後的數據集大小\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# 訓練隨機森林模型\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 評估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 確保索引的一致性\n",
    "print(f\"y_test index: {list(y_test.index)}\")\n",
    "\n",
    "# 獲取測試數據的索引\n",
    "test_indices = y_test.index\n",
    "\n",
    "# 如果需要將測試結果保存到Excel文件\n",
    "df_test = df.loc[test_indices].copy()\n",
    "df_test['predicted_label'] = y_pred\n",
    "df_test['predicted_course_level'] = df_test['predicted_label'].map({0: 'Beginner', 1: 'Intermediate', 2: 'Advanced'})\n",
    "\n",
    "test_output_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_test_with_predictions_2.xlsx'\n",
    "df_test.to_excel(test_output_file_path, index=False)\n",
    "\n",
    "print(\"模型訓練和預測完成，結果已保存到新的Excel文件。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix shape: (6055, 9946)\n",
      "Labels shape: (6055,)\n",
      "X_train shape: (4844, 9946)\n",
      "X_test shape: (1211, 9946)\n",
      "y_train shape: (4844,)\n",
      "y_test shape: (1211,)\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "244 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "296 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.75206377 0.75268233 0.75433309\n",
      " 0.75226889 0.75206206 0.75268105 0.75185695 0.75226932 0.75268169\n",
      " 0.75020576 0.74937974 0.75020576 0.7493808  0.74958678 0.74979275\n",
      " 0.74938017 0.74917355 0.74896694 0.74463151 0.74483812 0.74504452\n",
      " 0.74463151 0.74483812 0.74504452 0.74463151 0.74504473 0.74545753\n",
      " 0.74814135 0.74772834 0.74834753 0.74979339 0.74876076 0.74855393\n",
      " 0.74917419 0.74793516 0.74814178 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.74029736 0.74091677 0.74071037\n",
      " 0.74029736 0.74071016 0.74050376 0.74050376 0.74029736 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74256817 0.74236177 0.74236177 0.74194876 0.74194897 0.74194897\n",
      " 0.74153596 0.74132956 0.74153596 0.74091655 0.74132956 0.74029715\n",
      " 0.74112295 0.74132956 0.74070994 0.74112295 0.74132956 0.74091655\n",
      " 0.74070994 0.74029715 0.74029715 0.74070994 0.74029715 0.74029715\n",
      " 0.74029715 0.74029715 0.74029715 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096\n",
      " 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096 0.74009096]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Accuracy: 0.7555739058629232\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.99      0.86       887\n",
      "         1.0       0.70      0.12      0.20       286\n",
      "         2.0       0.45      0.13      0.20        38\n",
      "\n",
      "    accuracy                           0.76      1211\n",
      "   macro avg       0.64      0.41      0.42      1211\n",
      "weighted avg       0.74      0.76      0.68      1211\n",
      "\n",
      "y_test index: [5589, 730, 2543, 1550, 2468, 4579, 254, 2884, 2729, 4829, 1851, 3205, 2885, 3005, 5239, 5076, 1896, 2444, 6012, 2646, 5142, 4382, 534, 5352, 4685, 2435, 2010, 3394, 5747, 319, 5314, 707, 5971, 2376, 753, 1956, 5420, 2082, 2341, 5966, 4244, 3116, 5052, 23, 1259, 465, 2822, 2786, 3053, 79, 6040, 1618, 323, 3619, 5397, 1556, 5961, 4547, 5211, 5374, 894, 4904, 4815, 1158, 6142, 3453, 2934, 2230, 4150, 1531, 3391, 2250, 221, 5116, 2725, 807, 5351, 5032, 3581, 2853, 2288, 439, 2920, 4701, 5766, 2258, 5186, 5467, 1743, 1343, 757, 5037, 4555, 1461, 233, 2571, 5416, 1204, 4232, 2930, 5013, 84, 2297, 3472, 2511, 5050, 5234, 1012, 1305, 2648, 228, 1063, 5272, 4496, 2764, 3155, 3426, 5269, 3595, 5501, 5584, 5040, 5431, 37, 3065, 5953, 3489, 2488, 1640, 6007, 1800, 4440, 4165, 4127, 3296, 822, 717, 93, 5794, 5881, 2469, 5594, 3471, 3675, 1742, 1350, 4737, 5310, 1024, 4688, 1491, 3898, 1860, 408, 3194, 4022, 401, 2194, 1221, 6057, 3349, 4071, 2898, 4608, 5935, 167, 4454, 5286, 2246, 5872, 3174, 5930, 565, 814, 3421, 156, 1340, 3493, 756, 472, 31, 4438, 2014, 5197, 1869, 5311, 5015, 5301, 2358, 2217, 177, 5890, 5901, 3535, 5592, 1356, 1091, 3659, 5068, 1205, 2974, 4419, 2742, 1217, 553, 4649, 2909, 2109, 535, 4393, 6159, 4720, 80, 5401, 5645, 4634, 346, 5650, 3381, 3730, 4451, 5213, 308, 3201, 1354, 5781, 3816, 2700, 3419, 157, 3395, 5238, 5792, 4976, 506, 6124, 3967, 4432, 4010, 2477, 469, 5163, 263, 1831, 2615, 5121, 1825, 2276, 4690, 1038, 3997, 1133, 4260, 5468, 5788, 3240, 2820, 5337, 3099, 5206, 3292, 5198, 561, 3033, 1849, 2951, 4000, 2829, 5156, 4571, 50, 1057, 4779, 3097, 1962, 476, 3790, 2043, 4080, 2720, 2262, 2915, 1317, 4329, 5551, 4834, 6010, 2895, 5950, 296, 5309, 3613, 1100, 1514, 2657, 5692, 239, 2464, 199, 1681, 2630, 2275, 2901, 2363, 2959, 5892, 4597, 1748, 101, 1934, 3284, 259, 5949, 2936, 1163, 3947, 4271, 3651, 843, 4344, 4001, 4827, 3782, 2024, 4636, 942, 2176, 6109, 4272, 4683, 4282, 1325, 544, 2797, 5756, 530, 4378, 1453, 4068, 3510, 3039, 3327, 6143, 2958, 6031, 5706, 3862, 324, 2328, 4353, 325, 2773, 3449, 132, 4223, 4704, 836, 1232, 1428, 2318, 4137, 1153, 3950, 6177, 1582, 5008, 2418, 4153, 2478, 786, 3628, 3049, 371, 6179, 2033, 3841, 3181, 3184, 2263, 168, 5769, 4241, 5801, 2003, 198, 3073, 3557, 3243, 5886, 2723, 5737, 230, 6051, 1868, 3568, 4332, 3849, 2940, 2707, 5120, 2629, 17, 6136, 1175, 4303, 5225, 3047, 1482, 5588, 3911, 4602, 837, 1324, 4226, 2923, 2960, 5746, 3578, 2793, 5723, 841, 4487, 1475, 1433, 393, 1688, 279, 3618, 4687, 2818, 1330, 1323, 4757, 14, 3075, 1579, 4542, 4538, 6114, 3938, 410, 3797, 1740, 2587, 2266, 4791, 65, 3329, 1328, 2447, 1998, 1301, 351, 4027, 1234, 5119, 1629, 3635, 4003, 1785, 2102, 88, 3606, 4321, 1685, 3085, 501, 877, 2607, 4861, 1501, 4460, 936, 943, 4366, 420, 5164, 4039, 373, 5599, 4805, 5261, 2919, 1239, 5785, 3338, 1292, 812, 735, 3630, 5548, 2304, 5065, 4404, 2549, 4499, 2085, 3439, 1781, 181, 1966, 3213, 5398, 1275, 3564, 2667, 2475, 3527, 914, 5755, 1392, 3739, 2245, 5843, 5900, 538, 5221, 2093, 2731, 2650, 4502, 878, 4739, 3328, 5172, 1373, 5975, 918, 5217, 3933, 15, 5605, 3952, 3008, 5804, 3716, 2198, 1542, 1303, 3293, 2999, 4914, 2133, 1502, 2235, 1178, 5157, 3689, 1250, 2548, 4457, 1886, 4995, 5972, 2096, 827, 8, 4734, 3004, 2588, 5232, 1783, 5464, 4212, 4848, 2139, 426, 33, 1441, 44, 3737, 1454, 2749, 873, 6023, 4641, 996, 3912, 3811, 63, 5841, 4008, 4257, 4922, 3590, 1585, 5011, 3497, 2808, 4135, 1754, 3931, 886, 1675, 5586, 2662, 4113, 5988, 3598, 1887, 2750, 4355, 6146, 4516, 5053, 4202, 925, 4588, 1384, 473, 2269, 3233, 297, 303, 4346, 2644, 5531, 1599, 4125, 4705, 3326, 2470, 240, 1510, 3387, 5939, 2203, 3694, 4347, 2533, 4552, 1108, 3533, 4795, 1569, 5893, 1632, 1731, 3851, 333, 1188, 5740, 3324, 1995, 2184, 941, 1394, 2415, 1627, 2775, 3761, 247, 861, 3126, 5726, 1878, 4853, 2364, 3270, 3254, 4707, 2437, 5676, 2050, 2612, 5839, 5387, 729, 1802, 315, 2052, 3770, 149, 1426, 1528, 290, 453, 5989, 1173, 5446, 2634, 3018, 2596, 3468, 3406, 2753, 4784, 3853, 5976, 3452, 2104, 3438, 1206, 1170, 5200, 2002, 2771, 939, 4731, 5256, 5456, 1125, 3813, 349, 4403, 3444, 3871, 381, 2073, 2748, 5048, 422, 4057, 5375, 5885, 2795, 5920, 124, 102, 3247, 5851, 1602, 3021, 486, 1312, 2422, 5201, 135, 1095, 3266, 3809, 2017, 931, 2906, 3206, 5542, 4905, 1273, 3884, 5836, 4482, 1730, 5868, 1306, 2211, 5575, 1746, 4401, 144, 380, 1619, 4881, 3542, 121, 3545, 742, 3543, 5507, 418, 5876, 5345, 3108, 1830, 3256, 3658, 2160, 4065, 5423, 4448, 248, 5634, 4233, 5660, 447, 1616, 4858, 1169, 2604, 5556, 2433, 3749, 2229, 5210, 3024, 6118, 4490, 4256, 2852, 414, 883, 2946, 4899, 785, 1260, 1180, 2835, 5532, 4595, 5814, 4944, 5580, 720, 3512, 4181, 5143, 2225, 5249, 1826, 5806, 4803, 832, 2371, 3378, 3351, 1552, 5087, 208, 1645, 4453, 425, 3732, 2830, 5830, 4709, 5450, 110, 3263, 6099, 5209, 1667, 3711, 4906, 3973, 1127, 5089, 1788, 1872, 3600, 1307, 3023, 1796, 1459, 3956, 437, 4954, 2501, 3821, 2996, 107, 3068, 29, 2572, 5202, 3154, 6016, 5960, 882, 4230, 715, 3410, 5845, 3357, 5127, 4391, 1908, 4052, 4836, 4717, 3763, 1010, 2218, 2882, 6056, 1403, 179, 4993, 4046, 3614, 2308, 1164, 3688, 4610, 2769, 1289, 5277, 5241, 90, 5840, 5995, 1352, 4920, 1875, 755, 69, 1020, 3585, 3825, 1700, 4832, 1008, 6014, 5166, 895, 293, 5694, 5908, 445, 468, 5729, 4435, 432, 1452, 3939, 3748, 3101, 4874, 708, 2344, 245, 4359, 367, 2619, 5786, 5108, 3030, 5649, 3407, 5681, 4444, 1861, 3873, 4642, 1636, 555, 3208, 4613, 3088, 2708, 2295, 2162, 5158, 5502, 2804, 5765, 151, 4425, 1485, 3880, 3537, 1046, 4383, 5413, 2123, 5994, 1711, 3951, 3701, 5010, 5451, 1608, 879, 5441, 6160, 5964, 4142, 4786, 1763, 1611, 5992, 4078, 4578, 491, 5083, 4506, 2165, 3940, 471, 3261, 3152, 3079, 4942, 938, 5852, 4466, 1228, 1027, 1911, 4749, 3344, 5612, 354, 251, 185, 4775, 1614, 2280, 3236, 227, 5460, 3320, 1446, 1351, 4313, 3245, 4146, 5640, 3540, 3377, 5305, 1797, 3260, 5670, 1564, 292, 5672, 549, 1674, 4423, 2989, 3420, 1751, 2434, 2863, 3824, 1690, 5418, 3016, 3925, 3759, 1177, 2649, 1874, 1488, 1314, 2404, 744, 3164, 3902, 2760, 4900, 5587, 505, 1695, 272, 2285, 2299, 4863, 2481, 106, 5725, 4058, 1083, 1963, 1765, 4712, 5903, 1155, 4986, 2570, 416, 5642, 5061, 2681, 564, 478, 1857, 142, 4305, 1294, 2072, 2313, 736, 1215, 2581, 497, 2873, 5191, 3586, 2545, 852, 3259, 1156, 1537, 4470, 1493, 3753, 2326, 5005, 2537, 5544, 2816, 2047, 1761, 336, 5434, 2950, 4727, 2423, 4338, 4909, 1538, 5500, 3678, 855, 896, 286, 307, 4446, 4840, 4653, 5615, 4753, 1346, 5259, 1975, 71, 2390, 842, 3915, 1151, 1524, 5573, 6148, 868, 4458, 3072, 4855, 5751, 5355, 5865, 1226, 4445, 3817, 2654, 5412, 1109, 6050, 5282, 3720, 4421, 5459, 344, 2666, 1042, 4433, 47, 2535, 5372, 443, 2807, 5842, 2665, 3148, 2095, 6119, 2594, 1638, 2443, 1186, 979, 4038, 6025, 4650, 2926, 5787, 4449, 5432, 1243, 1319, 907, 5858, 183, 5482, 6003, 1366, 2357, 865, 3127, 1299, 4259, 3998, 2208, 485, 1375, 452, 1630, 4766, 30, 920, 1466, 3318, 1240, 100, 4178, 2530, 3358, 1651, 3437, 1990, 3960, 4713, 992, 5439, 1034, 5472, 109, 5978, 2964, 5208, 2952, 2536]\n",
      "模型訓練和預測完成，結果已保存到新的Excel文件。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import jieba\n",
    "\n",
    "# 讀取Excel文件\n",
    "file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/UdemyCourses.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 確保數據中沒有缺失值\n",
    "df = df.dropna()\n",
    "\n",
    "# 提取文本特徵\n",
    "df['text'] = df['course_title'] + ' ' + df['skill_gain'] \n",
    "\n",
    "# 分詞\n",
    "df['words'] = df['text'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "# 映射課程級別到數值標籤\n",
    "label_mapping = {'Beginner': 0, 'Intermediate': 1, 'Advanced': 2}\n",
    "df['label'] = df['course_level'].map(label_mapping)\n",
    "\n",
    "# 檢查是否存在NaN值並刪除\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# 使用TF-IDF提取文本特徵\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['words'])\n",
    "\n",
    "# 檢查數據集大小是否一致\n",
    "print(f\"TF-IDF Matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Labels shape: {df['label'].shape}\")\n",
    "\n",
    "# 劃分數據集，80%訓練數據和20%測試數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 檢查劃分後的數據集大小\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# 使用GridSearchCV調整隨機森林模型超參數\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "# 預測\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 評估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 確保索引的一致性\n",
    "print(f\"y_test index: {list(y_test.index)}\")\n",
    "\n",
    "# 獲取測試數據的索引\n",
    "test_indices = y_test.index\n",
    "\n",
    "# 如果需要將測試結果保存到Excel文件\n",
    "df_test = df.loc[test_indices].copy()\n",
    "df_test['predicted_label'] = y_pred\n",
    "df_test['predicted_course_level'] = df_test['predicted_label'].map({0: 'Beginner', 1: 'Intermediate', 2: 'Advanced'})\n",
    "\n",
    "test_output_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_test_with_predictions_2.xlsx'\n",
    "df_test.to_excel(test_output_file_path, index=False)\n",
    "\n",
    "print(\"模型訓練和預測完成，結果已保存到新的Excel文件。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其他方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\WCHuang8\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.828 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix shape: (6055, 9946)\n",
      "Labels shape: (6055,)\n",
      "X_train shape: (4844, 9946)\n",
      "X_test shape: (1211, 9946)\n",
      "y_train shape: (4844,)\n",
      "y_test shape: (1211,)\n",
      "Accuracy: 0.7522708505367465\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.95      0.86       887\n",
      "         1.0       0.55      0.23      0.32       286\n",
      "         2.0       0.33      0.11      0.16        38\n",
      "\n",
      "    accuracy                           0.75      1211\n",
      "   macro avg       0.55      0.43      0.45      1211\n",
      "weighted avg       0.71      0.75      0.71      1211\n",
      "\n",
      "y_test index: [5589, 730, 2543, 1550, 2468, 4579, 254, 2884, 2729, 4829, 1851, 3205, 2885, 3005, 5239, 5076, 1896, 2444, 6012, 2646, 5142, 4382, 534, 5352, 4685, 2435, 2010, 3394, 5747, 319, 5314, 707, 5971, 2376, 753, 1956, 5420, 2082, 2341, 5966, 4244, 3116, 5052, 23, 1259, 465, 2822, 2786, 3053, 79, 6040, 1618, 323, 3619, 5397, 1556, 5961, 4547, 5211, 5374, 894, 4904, 4815, 1158, 6142, 3453, 2934, 2230, 4150, 1531, 3391, 2250, 221, 5116, 2725, 807, 5351, 5032, 3581, 2853, 2288, 439, 2920, 4701, 5766, 2258, 5186, 5467, 1743, 1343, 757, 5037, 4555, 1461, 233, 2571, 5416, 1204, 4232, 2930, 5013, 84, 2297, 3472, 2511, 5050, 5234, 1012, 1305, 2648, 228, 1063, 5272, 4496, 2764, 3155, 3426, 5269, 3595, 5501, 5584, 5040, 5431, 37, 3065, 5953, 3489, 2488, 1640, 6007, 1800, 4440, 4165, 4127, 3296, 822, 717, 93, 5794, 5881, 2469, 5594, 3471, 3675, 1742, 1350, 4737, 5310, 1024, 4688, 1491, 3898, 1860, 408, 3194, 4022, 401, 2194, 1221, 6057, 3349, 4071, 2898, 4608, 5935, 167, 4454, 5286, 2246, 5872, 3174, 5930, 565, 814, 3421, 156, 1340, 3493, 756, 472, 31, 4438, 2014, 5197, 1869, 5311, 5015, 5301, 2358, 2217, 177, 5890, 5901, 3535, 5592, 1356, 1091, 3659, 5068, 1205, 2974, 4419, 2742, 1217, 553, 4649, 2909, 2109, 535, 4393, 6159, 4720, 80, 5401, 5645, 4634, 346, 5650, 3381, 3730, 4451, 5213, 308, 3201, 1354, 5781, 3816, 2700, 3419, 157, 3395, 5238, 5792, 4976, 506, 6124, 3967, 4432, 4010, 2477, 469, 5163, 263, 1831, 2615, 5121, 1825, 2276, 4690, 1038, 3997, 1133, 4260, 5468, 5788, 3240, 2820, 5337, 3099, 5206, 3292, 5198, 561, 3033, 1849, 2951, 4000, 2829, 5156, 4571, 50, 1057, 4779, 3097, 1962, 476, 3790, 2043, 4080, 2720, 2262, 2915, 1317, 4329, 5551, 4834, 6010, 2895, 5950, 296, 5309, 3613, 1100, 1514, 2657, 5692, 239, 2464, 199, 1681, 2630, 2275, 2901, 2363, 2959, 5892, 4597, 1748, 101, 1934, 3284, 259, 5949, 2936, 1163, 3947, 4271, 3651, 843, 4344, 4001, 4827, 3782, 2024, 4636, 942, 2176, 6109, 4272, 4683, 4282, 1325, 544, 2797, 5756, 530, 4378, 1453, 4068, 3510, 3039, 3327, 6143, 2958, 6031, 5706, 3862, 324, 2328, 4353, 325, 2773, 3449, 132, 4223, 4704, 836, 1232, 1428, 2318, 4137, 1153, 3950, 6177, 1582, 5008, 2418, 4153, 2478, 786, 3628, 3049, 371, 6179, 2033, 3841, 3181, 3184, 2263, 168, 5769, 4241, 5801, 2003, 198, 3073, 3557, 3243, 5886, 2723, 5737, 230, 6051, 1868, 3568, 4332, 3849, 2940, 2707, 5120, 2629, 17, 6136, 1175, 4303, 5225, 3047, 1482, 5588, 3911, 4602, 837, 1324, 4226, 2923, 2960, 5746, 3578, 2793, 5723, 841, 4487, 1475, 1433, 393, 1688, 279, 3618, 4687, 2818, 1330, 1323, 4757, 14, 3075, 1579, 4542, 4538, 6114, 3938, 410, 3797, 1740, 2587, 2266, 4791, 65, 3329, 1328, 2447, 1998, 1301, 351, 4027, 1234, 5119, 1629, 3635, 4003, 1785, 2102, 88, 3606, 4321, 1685, 3085, 501, 877, 2607, 4861, 1501, 4460, 936, 943, 4366, 420, 5164, 4039, 373, 5599, 4805, 5261, 2919, 1239, 5785, 3338, 1292, 812, 735, 3630, 5548, 2304, 5065, 4404, 2549, 4499, 2085, 3439, 1781, 181, 1966, 3213, 5398, 1275, 3564, 2667, 2475, 3527, 914, 5755, 1392, 3739, 2245, 5843, 5900, 538, 5221, 2093, 2731, 2650, 4502, 878, 4739, 3328, 5172, 1373, 5975, 918, 5217, 3933, 15, 5605, 3952, 3008, 5804, 3716, 2198, 1542, 1303, 3293, 2999, 4914, 2133, 1502, 2235, 1178, 5157, 3689, 1250, 2548, 4457, 1886, 4995, 5972, 2096, 827, 8, 4734, 3004, 2588, 5232, 1783, 5464, 4212, 4848, 2139, 426, 33, 1441, 44, 3737, 1454, 2749, 873, 6023, 4641, 996, 3912, 3811, 63, 5841, 4008, 4257, 4922, 3590, 1585, 5011, 3497, 2808, 4135, 1754, 3931, 886, 1675, 5586, 2662, 4113, 5988, 3598, 1887, 2750, 4355, 6146, 4516, 5053, 4202, 925, 4588, 1384, 473, 2269, 3233, 297, 303, 4346, 2644, 5531, 1599, 4125, 4705, 3326, 2470, 240, 1510, 3387, 5939, 2203, 3694, 4347, 2533, 4552, 1108, 3533, 4795, 1569, 5893, 1632, 1731, 3851, 333, 1188, 5740, 3324, 1995, 2184, 941, 1394, 2415, 1627, 2775, 3761, 247, 861, 3126, 5726, 1878, 4853, 2364, 3270, 3254, 4707, 2437, 5676, 2050, 2612, 5839, 5387, 729, 1802, 315, 2052, 3770, 149, 1426, 1528, 290, 453, 5989, 1173, 5446, 2634, 3018, 2596, 3468, 3406, 2753, 4784, 3853, 5976, 3452, 2104, 3438, 1206, 1170, 5200, 2002, 2771, 939, 4731, 5256, 5456, 1125, 3813, 349, 4403, 3444, 3871, 381, 2073, 2748, 5048, 422, 4057, 5375, 5885, 2795, 5920, 124, 102, 3247, 5851, 1602, 3021, 486, 1312, 2422, 5201, 135, 1095, 3266, 3809, 2017, 931, 2906, 3206, 5542, 4905, 1273, 3884, 5836, 4482, 1730, 5868, 1306, 2211, 5575, 1746, 4401, 144, 380, 1619, 4881, 3542, 121, 3545, 742, 3543, 5507, 418, 5876, 5345, 3108, 1830, 3256, 3658, 2160, 4065, 5423, 4448, 248, 5634, 4233, 5660, 447, 1616, 4858, 1169, 2604, 5556, 2433, 3749, 2229, 5210, 3024, 6118, 4490, 4256, 2852, 414, 883, 2946, 4899, 785, 1260, 1180, 2835, 5532, 4595, 5814, 4944, 5580, 720, 3512, 4181, 5143, 2225, 5249, 1826, 5806, 4803, 832, 2371, 3378, 3351, 1552, 5087, 208, 1645, 4453, 425, 3732, 2830, 5830, 4709, 5450, 110, 3263, 6099, 5209, 1667, 3711, 4906, 3973, 1127, 5089, 1788, 1872, 3600, 1307, 3023, 1796, 1459, 3956, 437, 4954, 2501, 3821, 2996, 107, 3068, 29, 2572, 5202, 3154, 6016, 5960, 882, 4230, 715, 3410, 5845, 3357, 5127, 4391, 1908, 4052, 4836, 4717, 3763, 1010, 2218, 2882, 6056, 1403, 179, 4993, 4046, 3614, 2308, 1164, 3688, 4610, 2769, 1289, 5277, 5241, 90, 5840, 5995, 1352, 4920, 1875, 755, 69, 1020, 3585, 3825, 1700, 4832, 1008, 6014, 5166, 895, 293, 5694, 5908, 445, 468, 5729, 4435, 432, 1452, 3939, 3748, 3101, 4874, 708, 2344, 245, 4359, 367, 2619, 5786, 5108, 3030, 5649, 3407, 5681, 4444, 1861, 3873, 4642, 1636, 555, 3208, 4613, 3088, 2708, 2295, 2162, 5158, 5502, 2804, 5765, 151, 4425, 1485, 3880, 3537, 1046, 4383, 5413, 2123, 5994, 1711, 3951, 3701, 5010, 5451, 1608, 879, 5441, 6160, 5964, 4142, 4786, 1763, 1611, 5992, 4078, 4578, 491, 5083, 4506, 2165, 3940, 471, 3261, 3152, 3079, 4942, 938, 5852, 4466, 1228, 1027, 1911, 4749, 3344, 5612, 354, 251, 185, 4775, 1614, 2280, 3236, 227, 5460, 3320, 1446, 1351, 4313, 3245, 4146, 5640, 3540, 3377, 5305, 1797, 3260, 5670, 1564, 292, 5672, 549, 1674, 4423, 2989, 3420, 1751, 2434, 2863, 3824, 1690, 5418, 3016, 3925, 3759, 1177, 2649, 1874, 1488, 1314, 2404, 744, 3164, 3902, 2760, 4900, 5587, 505, 1695, 272, 2285, 2299, 4863, 2481, 106, 5725, 4058, 1083, 1963, 1765, 4712, 5903, 1155, 4986, 2570, 416, 5642, 5061, 2681, 564, 478, 1857, 142, 4305, 1294, 2072, 2313, 736, 1215, 2581, 497, 2873, 5191, 3586, 2545, 852, 3259, 1156, 1537, 4470, 1493, 3753, 2326, 5005, 2537, 5544, 2816, 2047, 1761, 336, 5434, 2950, 4727, 2423, 4338, 4909, 1538, 5500, 3678, 855, 896, 286, 307, 4446, 4840, 4653, 5615, 4753, 1346, 5259, 1975, 71, 2390, 842, 3915, 1151, 1524, 5573, 6148, 868, 4458, 3072, 4855, 5751, 5355, 5865, 1226, 4445, 3817, 2654, 5412, 1109, 6050, 5282, 3720, 4421, 5459, 344, 2666, 1042, 4433, 47, 2535, 5372, 443, 2807, 5842, 2665, 3148, 2095, 6119, 2594, 1638, 2443, 1186, 979, 4038, 6025, 4650, 2926, 5787, 4449, 5432, 1243, 1319, 907, 5858, 183, 5482, 6003, 1366, 2357, 865, 3127, 1299, 4259, 3998, 2208, 485, 1375, 452, 1630, 4766, 30, 920, 1466, 3318, 1240, 100, 4178, 2530, 3358, 1651, 3437, 1990, 3960, 4713, 992, 5439, 1034, 5472, 109, 5978, 2964, 5208, 2952, 2536]\n",
      "模型訓練和預測完成，結果已保存到新的Excel文件。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import jieba\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 讀取Excel文件\n",
    "file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/UdemyCourses.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 確保數據中沒有缺失值\n",
    "df = df.dropna()\n",
    "\n",
    "# 提取文本特徵\n",
    "df['text'] = df['course_title'] + ' ' + df['skill_gain'] \n",
    "\n",
    "# 分詞\n",
    "df['words'] = df['text'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "# 映射課程級別到數值標籤\n",
    "label_mapping = {'Beginner': 0, 'Intermediate': 1, 'Advanced': 2}\n",
    "df['label'] = df['course_level'].map(label_mapping)\n",
    "\n",
    "# 檢查是否存在NaN值並刪除\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# 使用TF-IDF提取文本特徵\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['words'])\n",
    "\n",
    "# 檢查數據集大小是否一致\n",
    "print(f\"TF-IDF Matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Labels shape: {df['label'].shape}\")\n",
    "\n",
    "# 劃分數據集，80%訓練數據和20%測試數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 檢查劃分後的數據集大小\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# 訓練XGBoost模型\n",
    "clf = XGBClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 評估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 確保索引的一致性\n",
    "print(f\"y_test index: {list(y_test.index)}\")\n",
    "\n",
    "# 獲取測試數據的索引\n",
    "test_indices = y_test.index\n",
    "\n",
    "# 如果需要將測試結果保存到Excel文件\n",
    "df_test = df.loc[test_indices].copy()\n",
    "df_test['predicted_label'] = y_pred\n",
    "df_test['predicted_course_level'] = df_test['predicted_label'].map({0: 'Beginner', 1: 'Intermediate', 2: 'Advanced'})\n",
    "\n",
    "test_output_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_test_with_predictions_2.xlsx'\n",
    "df_test.to_excel(test_output_file_path, index=False)\n",
    "\n",
    "print(\"模型訓練和預測完成，結果已保存到新的Excel文件。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix shape: (6055, 9946)\n",
      "Labels shape: (6055,)\n",
      "X_train shape: (4844, 9946)\n",
      "X_test shape: (1211, 9946)\n",
      "y_train shape: (4844,)\n",
      "y_test shape: (1211,)\n",
      "Accuracy: 0.7555739058629232\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.98      0.86       887\n",
      "         1.0       0.61      0.16      0.25       286\n",
      "         2.0       0.43      0.08      0.13        38\n",
      "\n",
      "    accuracy                           0.76      1211\n",
      "   macro avg       0.60      0.40      0.41      1211\n",
      "weighted avg       0.72      0.76      0.69      1211\n",
      "\n",
      "y_test index: [5589, 730, 2543, 1550, 2468, 4579, 254, 2884, 2729, 4829, 1851, 3205, 2885, 3005, 5239, 5076, 1896, 2444, 6012, 2646, 5142, 4382, 534, 5352, 4685, 2435, 2010, 3394, 5747, 319, 5314, 707, 5971, 2376, 753, 1956, 5420, 2082, 2341, 5966, 4244, 3116, 5052, 23, 1259, 465, 2822, 2786, 3053, 79, 6040, 1618, 323, 3619, 5397, 1556, 5961, 4547, 5211, 5374, 894, 4904, 4815, 1158, 6142, 3453, 2934, 2230, 4150, 1531, 3391, 2250, 221, 5116, 2725, 807, 5351, 5032, 3581, 2853, 2288, 439, 2920, 4701, 5766, 2258, 5186, 5467, 1743, 1343, 757, 5037, 4555, 1461, 233, 2571, 5416, 1204, 4232, 2930, 5013, 84, 2297, 3472, 2511, 5050, 5234, 1012, 1305, 2648, 228, 1063, 5272, 4496, 2764, 3155, 3426, 5269, 3595, 5501, 5584, 5040, 5431, 37, 3065, 5953, 3489, 2488, 1640, 6007, 1800, 4440, 4165, 4127, 3296, 822, 717, 93, 5794, 5881, 2469, 5594, 3471, 3675, 1742, 1350, 4737, 5310, 1024, 4688, 1491, 3898, 1860, 408, 3194, 4022, 401, 2194, 1221, 6057, 3349, 4071, 2898, 4608, 5935, 167, 4454, 5286, 2246, 5872, 3174, 5930, 565, 814, 3421, 156, 1340, 3493, 756, 472, 31, 4438, 2014, 5197, 1869, 5311, 5015, 5301, 2358, 2217, 177, 5890, 5901, 3535, 5592, 1356, 1091, 3659, 5068, 1205, 2974, 4419, 2742, 1217, 553, 4649, 2909, 2109, 535, 4393, 6159, 4720, 80, 5401, 5645, 4634, 346, 5650, 3381, 3730, 4451, 5213, 308, 3201, 1354, 5781, 3816, 2700, 3419, 157, 3395, 5238, 5792, 4976, 506, 6124, 3967, 4432, 4010, 2477, 469, 5163, 263, 1831, 2615, 5121, 1825, 2276, 4690, 1038, 3997, 1133, 4260, 5468, 5788, 3240, 2820, 5337, 3099, 5206, 3292, 5198, 561, 3033, 1849, 2951, 4000, 2829, 5156, 4571, 50, 1057, 4779, 3097, 1962, 476, 3790, 2043, 4080, 2720, 2262, 2915, 1317, 4329, 5551, 4834, 6010, 2895, 5950, 296, 5309, 3613, 1100, 1514, 2657, 5692, 239, 2464, 199, 1681, 2630, 2275, 2901, 2363, 2959, 5892, 4597, 1748, 101, 1934, 3284, 259, 5949, 2936, 1163, 3947, 4271, 3651, 843, 4344, 4001, 4827, 3782, 2024, 4636, 942, 2176, 6109, 4272, 4683, 4282, 1325, 544, 2797, 5756, 530, 4378, 1453, 4068, 3510, 3039, 3327, 6143, 2958, 6031, 5706, 3862, 324, 2328, 4353, 325, 2773, 3449, 132, 4223, 4704, 836, 1232, 1428, 2318, 4137, 1153, 3950, 6177, 1582, 5008, 2418, 4153, 2478, 786, 3628, 3049, 371, 6179, 2033, 3841, 3181, 3184, 2263, 168, 5769, 4241, 5801, 2003, 198, 3073, 3557, 3243, 5886, 2723, 5737, 230, 6051, 1868, 3568, 4332, 3849, 2940, 2707, 5120, 2629, 17, 6136, 1175, 4303, 5225, 3047, 1482, 5588, 3911, 4602, 837, 1324, 4226, 2923, 2960, 5746, 3578, 2793, 5723, 841, 4487, 1475, 1433, 393, 1688, 279, 3618, 4687, 2818, 1330, 1323, 4757, 14, 3075, 1579, 4542, 4538, 6114, 3938, 410, 3797, 1740, 2587, 2266, 4791, 65, 3329, 1328, 2447, 1998, 1301, 351, 4027, 1234, 5119, 1629, 3635, 4003, 1785, 2102, 88, 3606, 4321, 1685, 3085, 501, 877, 2607, 4861, 1501, 4460, 936, 943, 4366, 420, 5164, 4039, 373, 5599, 4805, 5261, 2919, 1239, 5785, 3338, 1292, 812, 735, 3630, 5548, 2304, 5065, 4404, 2549, 4499, 2085, 3439, 1781, 181, 1966, 3213, 5398, 1275, 3564, 2667, 2475, 3527, 914, 5755, 1392, 3739, 2245, 5843, 5900, 538, 5221, 2093, 2731, 2650, 4502, 878, 4739, 3328, 5172, 1373, 5975, 918, 5217, 3933, 15, 5605, 3952, 3008, 5804, 3716, 2198, 1542, 1303, 3293, 2999, 4914, 2133, 1502, 2235, 1178, 5157, 3689, 1250, 2548, 4457, 1886, 4995, 5972, 2096, 827, 8, 4734, 3004, 2588, 5232, 1783, 5464, 4212, 4848, 2139, 426, 33, 1441, 44, 3737, 1454, 2749, 873, 6023, 4641, 996, 3912, 3811, 63, 5841, 4008, 4257, 4922, 3590, 1585, 5011, 3497, 2808, 4135, 1754, 3931, 886, 1675, 5586, 2662, 4113, 5988, 3598, 1887, 2750, 4355, 6146, 4516, 5053, 4202, 925, 4588, 1384, 473, 2269, 3233, 297, 303, 4346, 2644, 5531, 1599, 4125, 4705, 3326, 2470, 240, 1510, 3387, 5939, 2203, 3694, 4347, 2533, 4552, 1108, 3533, 4795, 1569, 5893, 1632, 1731, 3851, 333, 1188, 5740, 3324, 1995, 2184, 941, 1394, 2415, 1627, 2775, 3761, 247, 861, 3126, 5726, 1878, 4853, 2364, 3270, 3254, 4707, 2437, 5676, 2050, 2612, 5839, 5387, 729, 1802, 315, 2052, 3770, 149, 1426, 1528, 290, 453, 5989, 1173, 5446, 2634, 3018, 2596, 3468, 3406, 2753, 4784, 3853, 5976, 3452, 2104, 3438, 1206, 1170, 5200, 2002, 2771, 939, 4731, 5256, 5456, 1125, 3813, 349, 4403, 3444, 3871, 381, 2073, 2748, 5048, 422, 4057, 5375, 5885, 2795, 5920, 124, 102, 3247, 5851, 1602, 3021, 486, 1312, 2422, 5201, 135, 1095, 3266, 3809, 2017, 931, 2906, 3206, 5542, 4905, 1273, 3884, 5836, 4482, 1730, 5868, 1306, 2211, 5575, 1746, 4401, 144, 380, 1619, 4881, 3542, 121, 3545, 742, 3543, 5507, 418, 5876, 5345, 3108, 1830, 3256, 3658, 2160, 4065, 5423, 4448, 248, 5634, 4233, 5660, 447, 1616, 4858, 1169, 2604, 5556, 2433, 3749, 2229, 5210, 3024, 6118, 4490, 4256, 2852, 414, 883, 2946, 4899, 785, 1260, 1180, 2835, 5532, 4595, 5814, 4944, 5580, 720, 3512, 4181, 5143, 2225, 5249, 1826, 5806, 4803, 832, 2371, 3378, 3351, 1552, 5087, 208, 1645, 4453, 425, 3732, 2830, 5830, 4709, 5450, 110, 3263, 6099, 5209, 1667, 3711, 4906, 3973, 1127, 5089, 1788, 1872, 3600, 1307, 3023, 1796, 1459, 3956, 437, 4954, 2501, 3821, 2996, 107, 3068, 29, 2572, 5202, 3154, 6016, 5960, 882, 4230, 715, 3410, 5845, 3357, 5127, 4391, 1908, 4052, 4836, 4717, 3763, 1010, 2218, 2882, 6056, 1403, 179, 4993, 4046, 3614, 2308, 1164, 3688, 4610, 2769, 1289, 5277, 5241, 90, 5840, 5995, 1352, 4920, 1875, 755, 69, 1020, 3585, 3825, 1700, 4832, 1008, 6014, 5166, 895, 293, 5694, 5908, 445, 468, 5729, 4435, 432, 1452, 3939, 3748, 3101, 4874, 708, 2344, 245, 4359, 367, 2619, 5786, 5108, 3030, 5649, 3407, 5681, 4444, 1861, 3873, 4642, 1636, 555, 3208, 4613, 3088, 2708, 2295, 2162, 5158, 5502, 2804, 5765, 151, 4425, 1485, 3880, 3537, 1046, 4383, 5413, 2123, 5994, 1711, 3951, 3701, 5010, 5451, 1608, 879, 5441, 6160, 5964, 4142, 4786, 1763, 1611, 5992, 4078, 4578, 491, 5083, 4506, 2165, 3940, 471, 3261, 3152, 3079, 4942, 938, 5852, 4466, 1228, 1027, 1911, 4749, 3344, 5612, 354, 251, 185, 4775, 1614, 2280, 3236, 227, 5460, 3320, 1446, 1351, 4313, 3245, 4146, 5640, 3540, 3377, 5305, 1797, 3260, 5670, 1564, 292, 5672, 549, 1674, 4423, 2989, 3420, 1751, 2434, 2863, 3824, 1690, 5418, 3016, 3925, 3759, 1177, 2649, 1874, 1488, 1314, 2404, 744, 3164, 3902, 2760, 4900, 5587, 505, 1695, 272, 2285, 2299, 4863, 2481, 106, 5725, 4058, 1083, 1963, 1765, 4712, 5903, 1155, 4986, 2570, 416, 5642, 5061, 2681, 564, 478, 1857, 142, 4305, 1294, 2072, 2313, 736, 1215, 2581, 497, 2873, 5191, 3586, 2545, 852, 3259, 1156, 1537, 4470, 1493, 3753, 2326, 5005, 2537, 5544, 2816, 2047, 1761, 336, 5434, 2950, 4727, 2423, 4338, 4909, 1538, 5500, 3678, 855, 896, 286, 307, 4446, 4840, 4653, 5615, 4753, 1346, 5259, 1975, 71, 2390, 842, 3915, 1151, 1524, 5573, 6148, 868, 4458, 3072, 4855, 5751, 5355, 5865, 1226, 4445, 3817, 2654, 5412, 1109, 6050, 5282, 3720, 4421, 5459, 344, 2666, 1042, 4433, 47, 2535, 5372, 443, 2807, 5842, 2665, 3148, 2095, 6119, 2594, 1638, 2443, 1186, 979, 4038, 6025, 4650, 2926, 5787, 4449, 5432, 1243, 1319, 907, 5858, 183, 5482, 6003, 1366, 2357, 865, 3127, 1299, 4259, 3998, 2208, 485, 1375, 452, 1630, 4766, 30, 920, 1466, 3318, 1240, 100, 4178, 2530, 3358, 1651, 3437, 1990, 3960, 4713, 992, 5439, 1034, 5472, 109, 5978, 2964, 5208, 2952, 2536]\n",
      "模型訓練和預測完成，結果已保存到新的Excel文件。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import jieba\n",
    "\n",
    "# 讀取Excel文件\n",
    "file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/UdemyCourses.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 確保數據中沒有缺失值\n",
    "df = df.dropna()\n",
    "\n",
    "# 提取文本特徵\n",
    "df['text'] = df['course_title'] + ' ' + df['skill_gain'] \n",
    "\n",
    "# 分詞\n",
    "df['words'] = df['text'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "# 映射課程級別到數值標籤\n",
    "label_mapping = {'Beginner': 0, 'Intermediate': 1, 'Advanced': 2}\n",
    "df['label'] = df['course_level'].map(label_mapping)\n",
    "\n",
    "# 檢查是否存在NaN值並刪除\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# 使用TF-IDF提取文本特徵\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['words'])\n",
    "\n",
    "# 檢查數據集大小是否一致\n",
    "print(f\"TF-IDF Matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Labels shape: {df['label'].shape}\")\n",
    "\n",
    "# 劃分數據集，80%訓練數據和20%測試數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 檢查劃分後的數據集大小\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# 訓練SVM模型\n",
    "clf = SVC(kernel='linear', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 評估模型\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 確保索引的一致性\n",
    "print(f\"y_test index: {list(y_test.index)}\")\n",
    "\n",
    "# 獲取測試數據的索引\n",
    "test_indices = y_test.index\n",
    "\n",
    "# 如果需要將測試結果保存到Excel文件\n",
    "df_test = df.loc[test_indices].copy()\n",
    "df_test['predicted_label'] = y_pred\n",
    "df_test['predicted_course_level'] = df_test['predicted_label'].map({0: 'Beginner', 1: 'Intermediate', 2: 'Advanced'})\n",
    "\n",
    "test_output_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_test_with_predictions_2.xlsx'\n",
    "df_test.to_excel(test_output_file_path, index=False)\n",
    "\n",
    "print(\"模型訓練和預測完成，結果已保存到新的Excel文件。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.7361 - loss: 0.7101 - val_accuracy: 0.7234 - val_loss: 0.6396\n",
      "Epoch 2/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.7688 - loss: 0.5051 - val_accuracy: 0.7183 - val_loss: 0.7496\n",
      "Epoch 3/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8857 - loss: 0.3112 - val_accuracy: 0.6894 - val_loss: 0.8438\n",
      "Epoch 4/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9467 - loss: 0.1517 - val_accuracy: 0.6852 - val_loss: 1.2277\n",
      "Epoch 5/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9733 - loss: 0.0784 - val_accuracy: 0.6987 - val_loss: 1.5148\n",
      "Epoch 6/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9870 - loss: 0.0450 - val_accuracy: 0.7049 - val_loss: 1.8664\n",
      "Epoch 7/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9947 - loss: 0.0227 - val_accuracy: 0.6894 - val_loss: 2.0840\n",
      "Epoch 8/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9972 - loss: 0.0141 - val_accuracy: 0.7028 - val_loss: 2.2835\n",
      "Epoch 9/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9961 - loss: 0.0107 - val_accuracy: 0.6708 - val_loss: 2.2882\n",
      "Epoch 10/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9963 - loss: 0.0145 - val_accuracy: 0.6832 - val_loss: 2.4280\n",
      "Epoch 11/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9997 - loss: 0.0038 - val_accuracy: 0.6646 - val_loss: 2.3621\n",
      "Epoch 12/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0149 - val_accuracy: 0.6667 - val_loss: 2.4647\n",
      "Epoch 13/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9989 - loss: 0.0078 - val_accuracy: 0.6956 - val_loss: 2.8905\n",
      "Epoch 14/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.6966 - val_loss: 2.8788\n",
      "Epoch 15/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.6832 - val_loss: 3.1787\n",
      "Epoch 16/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0046 - val_accuracy: 0.6894 - val_loss: 2.9937\n",
      "Epoch 17/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0100 - val_accuracy: 0.6956 - val_loss: 3.0490\n",
      "Epoch 18/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0052 - val_accuracy: 0.6904 - val_loss: 2.8573\n",
      "Epoch 19/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.6883 - val_loss: 2.7366\n",
      "Epoch 20/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0055 - val_accuracy: 0.7049 - val_loss: 2.9032\n",
      "Epoch 21/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9972 - loss: 0.0055 - val_accuracy: 0.6780 - val_loss: 2.9819\n",
      "Epoch 22/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.7110 - val_loss: 3.7994\n",
      "Epoch 23/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0092 - val_accuracy: 0.6914 - val_loss: 3.3020\n",
      "Epoch 24/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9981 - loss: 0.0043 - val_accuracy: 0.6935 - val_loss: 3.5011\n",
      "Epoch 25/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0027 - val_accuracy: 0.7162 - val_loss: 3.8507\n",
      "Epoch 26/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9975 - loss: 0.0066 - val_accuracy: 0.7038 - val_loss: 3.3814\n",
      "Epoch 27/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.6883 - val_loss: 3.2612\n",
      "Epoch 28/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.6821 - val_loss: 3.2611\n",
      "Epoch 29/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0058 - val_accuracy: 0.7007 - val_loss: 4.1059\n",
      "Epoch 30/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.7079 - val_loss: 4.5134\n",
      "Epoch 31/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9974 - loss: 0.0099 - val_accuracy: 0.6687 - val_loss: 3.7926\n",
      "Epoch 32/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9955 - loss: 0.0235 - val_accuracy: 0.7018 - val_loss: 3.5812\n",
      "Epoch 33/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.6987 - val_loss: 3.7326\n",
      "Epoch 34/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7018 - val_loss: 3.7520\n",
      "Epoch 35/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.6935 - val_loss: 3.8435\n",
      "Epoch 36/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0025 - val_accuracy: 0.7121 - val_loss: 4.2315\n",
      "Epoch 37/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.7028 - val_loss: 3.9590\n",
      "Epoch 38/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 7.3418e-04 - val_accuracy: 0.6997 - val_loss: 4.2563\n",
      "Epoch 39/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 6.5515e-04 - val_accuracy: 0.6914 - val_loss: 4.4506\n",
      "Epoch 40/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7079 - val_loss: 4.9325\n",
      "Epoch 41/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.6306e-04 - val_accuracy: 0.6997 - val_loss: 4.6549\n",
      "Epoch 42/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 8.5767e-04 - val_accuracy: 0.7110 - val_loss: 5.5864\n",
      "Epoch 43/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.6987 - val_loss: 4.8636\n",
      "Epoch 44/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.3235e-04 - val_accuracy: 0.6945 - val_loss: 4.7687\n",
      "Epoch 45/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 3.0768e-04 - val_accuracy: 0.7110 - val_loss: 5.6151\n",
      "Epoch 46/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.7028 - val_loss: 5.3364\n",
      "Epoch 47/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 6.0190e-04 - val_accuracy: 0.6956 - val_loss: 4.9826\n",
      "Epoch 48/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 3.4966e-04 - val_accuracy: 0.6883 - val_loss: 4.9684\n",
      "Epoch 49/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.8439e-04 - val_accuracy: 0.6925 - val_loss: 4.9213\n",
      "Epoch 50/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.9998 - loss: 7.4468e-04 - val_accuracy: 0.6976 - val_loss: 4.9517\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.89      0.82       887\n",
      "         1.0       0.40      0.22      0.28       286\n",
      "         2.0       0.10      0.08      0.09        38\n",
      "\n",
      "    accuracy                           0.70      1211\n",
      "   macro avg       0.42      0.40      0.40      1211\n",
      "weighted avg       0.66      0.70      0.67      1211\n",
      "\n",
      "Accuracy: 0.70355078447564\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test_labels, y_pred))\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# 如果需要將測試結果保存到Excel文件\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m df_test \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[43my_test_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     79\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred\n\u001b[0;32m     80\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_course_level\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeginner\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntermediate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdvanced\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import jieba\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# 讀取Excel文件\n",
    "file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/UdemyCourses.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 確保數據中沒有缺失值\n",
    "df = df.dropna()\n",
    "\n",
    "# 提取文本特徵\n",
    "df['text'] = df['course_title'] + ' ' + df['skill_gain'] \n",
    "\n",
    "# 分詞\n",
    "df['words'] = df['text'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "# 映射課程級別到數值標籤\n",
    "label_mapping = {'Beginner': 0, 'Intermediate': 1, 'Advanced': 2}\n",
    "df['label'] = df['course_level'].map(label_mapping)\n",
    "\n",
    "# 檢查是否存在NaN值並刪除\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# 將文本轉換為序列\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['words'])\n",
    "sequences = tokenizer.texts_to_sequences(df['words'])\n",
    "\n",
    "# 進行填充，使所有序列具有相同長度\n",
    "max_len = 100\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# 將標籤進行One-Hot編碼\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(df['label'])\n",
    "\n",
    "# 劃分數據集，80%訓練數據和20%測試數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 構建CNN模型\n",
    "vocab_size = len(tokenizer.word_index) + 1  # 加1是因為索引從1開始\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))  # 3個類別\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 預測\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 評估模型\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred, target_names=lb.classes_.astype(str)))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_labels, y_pred))\n",
    "\n",
    "# 如果需要將測試結果保存到Excel文件\n",
    "df_test = df.iloc[y_test_labels.index].copy()\n",
    "df_test['predicted_label'] = y_pred\n",
    "df_test['predicted_course_level'] = df_test['predicted_label'].map({0: 'Beginner', 1: 'Intermediate', 2: 'Advanced'})\n",
    "\n",
    "test_output_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_test_with_predictions_cnn.xlsx'\n",
    "df_test.to_excel(test_output_file_path, index=False)\n",
    "\n",
    "print(\"模型訓練和預測完成，結果已保存到新的Excel文件。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7392 - loss: 0.7391 - val_accuracy: 0.7234 - val_loss: 0.6458 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7338 - loss: 0.5803 - val_accuracy: 0.7193 - val_loss: 0.6491 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8155 - loss: 0.4302 - val_accuracy: 0.6801 - val_loss: 0.8197 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8894 - loss: 0.2828 - val_accuracy: 0.6760 - val_loss: 0.9776 - learning_rate: 2.0000e-04\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      1.00      0.85       887\n",
      "         1.0       0.00      0.00      0.00       286\n",
      "         2.0       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.73      1211\n",
      "   macro avg       0.24      0.33      0.28      1211\n",
      "weighted avg       0.54      0.73      0.62      1211\n",
      "\n",
      "Accuracy: 0.7324525185796862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test_labels, y_pred))\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# 如果需要將測試結果保存到Excel文件\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m df_test \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[43my_test_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     83\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred\n\u001b[0;32m     84\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_course_level\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeginner\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntermediate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdvanced\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import jieba\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Embedding, Dropout, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# 讀取Excel文件\n",
    "file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/UdemyCourses.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 確保數據中沒有缺失值\n",
    "df = df.dropna()\n",
    "\n",
    "# 提取文本特徵\n",
    "df['text'] = df['course_title'] + ' ' + df['skill_gain'] \n",
    "\n",
    "# 分詞\n",
    "df['words'] = df['text'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "# 映射課程級別到數值標籤\n",
    "label_mapping = {'Beginner': 0, 'Intermediate': 1, 'Advanced': 2}\n",
    "df['label'] = df['course_level'].map(label_mapping)\n",
    "\n",
    "# 檢查是否存在NaN值並刪除\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# 將文本轉換為序列\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['words'])\n",
    "sequences = tokenizer.texts_to_sequences(df['words'])\n",
    "\n",
    "# 進行填充，使所有序列具有相同長度\n",
    "max_len = 100\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# 將標籤進行One-Hot編碼\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(df['label'])\n",
    "\n",
    "# 劃分數據集，80%訓練數據和20%測試數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 構建CNN模型\n",
    "vocab_size = len(tokenizer.word_index) + 1  # 加1是因為索引從1開始\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))  # 3個類別\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# 預測\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 評估模型\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred, target_names=lb.classes_.astype(str)))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_labels, y_pred))\n",
    "\n",
    "# 如果需要將測試結果保存到Excel文件\n",
    "df_test = df.iloc[y_test_labels.index].copy()\n",
    "df_test['predicted_label'] = y_pred\n",
    "df_test['predicted_course_level'] = df_test['predicted_label'].map({0: 'Beginner', 1: 'Intermediate', 2: 'Advanced'})\n",
    "\n",
    "test_output_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_test_with_predictions_cnn.xlsx'\n",
    "df_test.to_excel(test_output_file_path, index=False)\n",
    "\n",
    "print(\"模型訓練和預測完成，結果已保存到新的Excel文件。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:數據集大小: (6055, 10)\n",
      "INFO:root:訓練集大小: (4844, 100), 測試集大小: (1211, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.7055 - loss: 0.8067 - val_accuracy: 0.7234 - val_loss: 0.7041 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.7486 - loss: 0.6890 - val_accuracy: 0.7183 - val_loss: 0.6478 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.8195 - loss: 0.4838 - val_accuracy: 0.7183 - val_loss: 0.7257 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 0.8812 - loss: 0.3364 - val_accuracy: 0.6894 - val_loss: 0.8694 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.9364 - loss: 0.2079 - val_accuracy: 0.6945 - val_loss: 1.0523 - learning_rate: 2.0000e-04\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\WCHuang8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "ERROR:root:訓練過程中發生錯誤: 'numpy.ndarray' object has no attribute 'index'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.94      0.86       887\n",
      "         1.0       0.54      0.29      0.38       286\n",
      "         2.0       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.76      1211\n",
      "   macro avg       0.44      0.41      0.41      1211\n",
      "weighted avg       0.70      0.76      0.72      1211\n",
      "\n",
      "Accuracy: 0.7572254335260116\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import jieba\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# 日誌記錄\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# 讀取Excel文件\n",
    "file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/UdemyCourses.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 確保數據中沒有缺失值\n",
    "df = df.dropna()\n",
    "\n",
    "# 提取文本特徵\n",
    "df['text'] = df['course_title'] + ' ' + df['skill_gain']\n",
    "\n",
    "# 分詞\n",
    "df['words'] = df['text'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "# 映射課程級別到數值標籤\n",
    "label_mapping = {'Beginner': 0, 'Intermediate': 1, 'Advanced': 2}\n",
    "df['label'] = df['course_level'].map(label_mapping)\n",
    "\n",
    "# 檢查是否存在NaN值並刪除\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# 日誌記錄：顯示數據集的大小\n",
    "logging.info(f\"數據集大小: {df.shape}\")\n",
    "\n",
    "# 將文本轉換為序列\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['words'])\n",
    "sequences = tokenizer.texts_to_sequences(df['words'])\n",
    "\n",
    "# 進行填充，使所有序列具有相同長度\n",
    "max_len = 100\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# 將標籤進行One-Hot編碼\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(df['label'])\n",
    "\n",
    "# 劃分數據集，80%訓練數據和20%測試數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 日誌記錄：顯示訓練集和測試集的大小\n",
    "logging.info(f\"訓練集大小: {X_train.shape}, 測試集大小: {X_test.shape}\")\n",
    "\n",
    "try:\n",
    "    # 構建LSTM模型\n",
    "    vocab_size = len(tokenizer.word_index) + 1  # 加1是因為索引從1開始\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
    "    model.add(LSTM(64, return_sequences=True))  # 減少LSTM單元數\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32))  # 減少LSTM單元數\n",
    "    model.add(Dense(64, activation='relu'))  # 減少Dense單元數\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))  # 3個類別\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 訓練模型\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    # 預測\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # 評估模型\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test_labels, y_pred, target_names=lb.classes_.astype(str)))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_labels, y_pred))\n",
    "\n",
    "    # 如果需要將測試結果保存到Excel文件\n",
    "    df_test = df.iloc[X_test.index].copy()  # 使用X_test的索引\n",
    "    df_test['predicted_label'] = y_pred\n",
    "    df_test['predicted_course_level'] = df_test['predicted_label'].map({0: 'Beginner', 1: 'Intermediate', 2: 'Advanced'})\n",
    "\n",
    "    test_output_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/course_data_test_with_predictions_lstm.xlsx'\n",
    "    df_test.to_excel(test_output_file_path, index=False)\n",
    "\n",
    "    print(\"模型訓練和預測完成，結果已保存到新的Excel文件。\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"訓練過程中發生錯誤: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "助手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "準確率: 36.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# 讀取本地文件\n",
    "file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/Course_Title_and_Level.csv'\n",
    "user_classification_file_path = 'C:/Users/WCHuang8/Desktop/學習推薦系統專案/model/user_classification_results.xlsx'\n",
    "\n",
    "# 加載數據\n",
    "course_data = pd.read_csv(file_path)\n",
    "user_classification_data = pd.read_excel(user_classification_file_path)\n",
    "\n",
    "# 提取所需的列\n",
    "course_data = course_data[['course_title', 'course_level']]\n",
    "user_classification_data = user_classification_data[['course_title', 'course_level']]\n",
    "\n",
    "# 定義一個函數來找到每個課程標題的最接近匹配\n",
    "def find_closest_match(title, title_list):\n",
    "    matches = get_close_matches(title, title_list, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "# 應用該函數來找到原始數據中最接近的課程標題\n",
    "original_titles = set(course_data['course_title'])\n",
    "user_classification_data['matched_title'] = user_classification_data['course_title'].apply(lambda x: find_closest_match(x, original_titles))\n",
    "\n",
    "# 合併數據集並比較課程等級\n",
    "merged_data = pd.merge(course_data, user_classification_data, left_on='course_title', right_on='matched_title', suffixes=('_original', '_classified'))\n",
    "merged_data['is_correct'] = merged_data['course_level_original'] == merged_data['course_level_classified']\n",
    "\n",
    "# 計算準確率\n",
    "accuracy = merged_data['is_correct'].mean()\n",
    "\n",
    "print(f\"準確率: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
